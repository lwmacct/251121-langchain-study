# ä»£ç å¯¹æ¯”ï¼šåŒä¸€ä¸ªåŠŸèƒ½ï¼Œä¸¤ç§å®ç°

## åœºæ™¯ï¼šç”¨æˆ·é—® "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿå¸®æˆ‘ç®— 2+3"

è¿™ä¸ªåœºæ™¯éœ€è¦è°ƒç”¨ 2 ä¸ªå·¥å…·ï¼š`get_current_time` å’Œ `calculator`

---

## 03 çš„å®ç°ï¼šæ‰‹åŠ¨å¾ªç¯ + æ‰‹åŠ¨å·¥å…·æ‰§è¡Œ

### agent.py (186 è¡Œ)

```python
class Agent:
    def __init__(self, tools: list[BaseTool]):
        self.llm = ChatOpenAI(...)
        self.llm_with_tools = self.llm.bind_tools(tools)  # âœ… ç”¨äº† bind_tools
        self.tools_map = {tool.name: tool for tool in tools}  # âŒ æ‰‹åŠ¨æ˜ å°„

    def chat(self, user_input: str, history: list) -> tuple[str, list[str] | None]:
        messages = [SystemMessage(...)]
        messages.extend(history)
        messages.append(HumanMessage(content=user_input))

        tool_calls_made = []

        # âŒ æ‰‹åŠ¨å¾ªç¯
        max_iterations = 5
        for iteration in range(max_iterations):
            try:
                # âŒ æ‰‹åŠ¨è°ƒç”¨ LLM
                response = self.llm_with_tools.invoke(messages)

                # âŒ æ‰‹åŠ¨åˆå¹¶ valid å’Œ invalid tool callsï¼ˆ20+ è¡Œï¼‰
                all_tool_calls = []
                if response.tool_calls:
                    all_tool_calls.extend(response.tool_calls)

                if hasattr(response, "invalid_tool_calls") and response.invalid_tool_calls:
                    for invalid_tc in response.invalid_tool_calls:
                        if invalid_tc.get("args") is None:
                            fixed_tc = {
                                "name": invalid_tc["name"],
                                "args": {},
                                "id": invalid_tc["id"],
                                "type": invalid_tc.get("type", "function"),
                            }
                            all_tool_calls.append(fixed_tc)
                            if config.debug:
                                console.print(f"âš ï¸  ä¿®å¤æ— å‚æ•°å·¥å…·è°ƒç”¨: {invalid_tc['name']}")
                        else:
                            if config.debug:
                                console.print(f"è­¦å‘Š: è·³è¿‡æ— æ•ˆå·¥å…·è°ƒç”¨: {invalid_tc}")

                # âŒ æ‰‹åŠ¨æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if not all_tool_calls:
                    return response.content, tool_calls_made if tool_calls_made else None

                # âŒ æ‰‹åŠ¨åˆ›å»ºæ¸…ç†è¿‡çš„ AIMessage
                clean_response = AIMessage(
                    content=response.content,
                    tool_calls=all_tool_calls,
                    id=response.id,
                )
                messages.append(clean_response)

                # âŒ æ‰‹åŠ¨æ‰§è¡Œæ¯ä¸ªå·¥å…·ï¼ˆ30+ è¡Œï¼‰
                for tool_call in all_tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    tool_id = tool_call["id"]

                    if config.debug:
                        console.print(f"â†’ å·¥å…·è°ƒç”¨: {tool_name}({tool_args})")

                    # âŒ æ‰‹åŠ¨æŸ¥æ‰¾å·¥å…·
                    if tool_name in self.tools_map:
                        try:
                            tool = self.tools_map[tool_name]
                            # âŒ æ‰‹åŠ¨æ‰§è¡Œå·¥å…·
                            result = tool.invoke(tool_args)
                            tool_calls_made.append(tool_name)

                            if config.debug:
                                console.print(f"â† å·¥å…·ç»“æœ: {result}")

                            # âŒ æ‰‹åŠ¨æ·»åŠ  ToolMessage
                            messages.append(
                                ToolMessage(
                                    content=str(result),
                                    tool_call_id=tool_id,
                                    name=tool_name,
                                )
                            )
                        except Exception as e:
                            # âŒ æ‰‹åŠ¨é”™è¯¯å¤„ç†
                            error_msg = f"å·¥å…·æ‰§è¡Œé”™è¯¯ï¼š{e}"
                            console.print(f"[red]{error_msg}[/red]")
                            messages.append(
                                ToolMessage(
                                    content=error_msg,
                                    tool_call_id=tool_id,
                                    name=tool_name,
                                )
                            )
                    else:
                        # âŒ æ‰‹åŠ¨å¤„ç†æœªçŸ¥å·¥å…·
                        error_msg = f"æœªçŸ¥å·¥å…·ï¼š{tool_name}"
                        messages.append(
                            ToolMessage(
                                content=error_msg,
                                tool_call_id=tool_id,
                                name=tool_name,
                            )
                        )

                # âŒ ç»§ç»­å¾ªç¯ï¼Œè®© LLM åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤

            except Exception as e:
                console.print(f"[red]Agent é”™è¯¯ï¼š{e}[/red]")
                return f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™ï¼š{e}", None

        # âŒ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        return "æŠ±æ­‰ï¼Œå·¥å…·è°ƒç”¨æ¬¡æ•°è¿‡å¤šï¼Œè¯·ç®€åŒ–æ‚¨çš„é—®é¢˜ã€‚", tool_calls_made
```

### session.py (98 è¡Œ)

```python
@dataclass
class Session:
    history: list[BaseMessage] = field(default_factory=list)
    max_history: int = 50

    def add_user_message(self, content: str) -> None:
        self.history.append(HumanMessage(content=content))
        self._trim_history()  # âŒ æ‰‹åŠ¨ç®¡ç†

    def add_assistant_message(self, content: str) -> None:
        self.history.append(AIMessage(content=content))
        self._trim_history()  # âŒ æ‰‹åŠ¨ç®¡ç†

    def get_history(self) -> list[BaseMessage]:
        return self.history.copy()  # âŒ æ‰‹åŠ¨å¤åˆ¶

    def _trim_history(self) -> None:
        if len(self.history) > self.max_history:
            self.history = self.history[-self.max_history :]  # âŒ æ‰‹åŠ¨ä¿®å‰ª

    # ... è¿˜æœ‰ render_history, get_message_count, iter_pairs ç­‰æ–¹æ³•
```

### main.py (ä¸»å¾ªç¯)

```python
def main():
    agent = create_agent()  # âŒ éœ€è¦å·¥å‚å‡½æ•°
    session = Session()  # âŒ éœ€è¦ Session ç±»

    for user_input, from_pipe in input_iterator:
        # âŒ æ‰‹åŠ¨æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        session.add_user_message(user_input)

        try:
            # âŒ æ‰‹åŠ¨è°ƒç”¨ Agentï¼ˆä¼ é€’å†å²ï¼‰
            reply, tool_calls = agent.chat(user_input, session.get_history()[:-1])

            # âŒ æ‰‹åŠ¨æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
            session.add_assistant_message(reply)

            # âŒ æ‰‹åŠ¨æ‰“å°ï¼ˆæ— æ³•å®æ—¶å±•ç¤ºå·¥å…·è°ƒç”¨ï¼‰
            print_assistant(reply, tool_calls)

        except Exception as e:
            error_msg = f"å¤„ç†å¤±è´¥ï¼š{e}"
            print_error(error_msg)
            session.add_assistant_message(f"[é”™è¯¯] {error_msg}")
```

**æ€»è¡Œæ•°ï¼š~400 è¡Œï¼ˆagent.py 186 + session.py 98 + main.py 126ï¼‰**

---

## 06 çš„å®ç°ï¼šLangGraph è‡ªåŠ¨åŒ–

### main.pyï¼ˆå®Œæ•´å®ç°ï¼Œä»… 212 è¡Œï¼‰

```python
import operator
from typing import Annotated, Sequence, TypedDict
from langchain_core.messages import AnyMessage, HumanMessage, ToolMessage
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
from rich.console import Console

import tools

# ===== åˆå§‹åŒ– =====
console = Console()
llm = ChatOpenAI(...)

# ===== é…ç½®å·¥å…·ï¼ˆä»… 3 è¡Œï¼‰ =====
tool_list = [tools.get_current_time, tools.calculator]
tool_node = ToolNode(tool_list)  # âœ… è‡ªåŠ¨æ‰§è¡Œå·¥å…·
llm_with_tools = llm.bind_tools(tool_list)

# ===== å®šä¹‰çŠ¶æ€ï¼ˆä»… 3 è¡Œï¼‰ =====
class State(TypedDict):
    messages: Annotated[Sequence[AnyMessage], operator.add]

# ===== å®šä¹‰èŠ‚ç‚¹ï¼ˆä»… 6 è¡Œï¼‰ =====
def call_model(state: State) -> State:
    """è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·ï¼‰"""
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}

def should_continue(state: State):
    """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è°ƒç”¨å·¥å…·"""
    if state["messages"][-1].tool_calls:
        return "tools"  # âœ… è‡ªåŠ¨è·¯ç”±åˆ°å·¥å…·èŠ‚ç‚¹
    return END

# ===== æ„å»ºå›¾ï¼ˆä»… 10 è¡Œï¼‰ =====
graph = StateGraph(State)
graph.add_node("model", call_model)
graph.add_node("tools", tool_node)  # âœ… ToolNode è‡ªåŠ¨æ‰§è¡Œæ‰€æœ‰å·¥å…·
graph.add_edge(START, "model")
graph.add_conditional_edges(
    "model",
    should_continue,
    {"tools": "tools", END: END}
)
graph.add_edge("tools", "model")  # å·¥å…·æ‰§è¡Œåè¿”å›æ¨¡å‹
app = graph.compile()

# ===== ä¸»å¾ªç¯ï¼ˆä»… 30 è¡Œï¼‰ =====
def main():
    messages = []  # âœ… ç®€å•çš„åˆ—è¡¨ï¼Œæ— éœ€ Session ç±»

    while True:
        user_input = Prompt.ask("ğŸ’¬ You")
        if user_input.lower() in ["exit", "quit"]:
            break

        # âœ… æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.append(HumanMessage(content=user_input))

        # âœ… æµå¼æ‰§è¡Œå›¾ï¼ˆè‡ªåŠ¨å¤„ç†æ‰€æœ‰é€»è¾‘ï¼‰
        for output in app.stream({"messages": messages}):
            for node_name, state in output.items():
                new_messages = state["messages"]

                # âœ… å¤„ç†æ¨¡å‹èŠ‚ç‚¹è¾“å‡º
                if node_name == "model":
                    last_message = new_messages[-1]

                    # âœ… å®æ—¶å±•ç¤ºå·¥å…·è°ƒç”¨
                    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                        for tool_call in last_message.tool_calls:
                            console.print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}({tool_call['args']})")

                    # âœ… å®æ—¶å±•ç¤º LLM å›å¤
                    if last_message.content:
                        console.print(f"ğŸ¤– Assistant: {last_message.content}")

                # âœ… å¤„ç†å·¥å…·èŠ‚ç‚¹è¾“å‡º
                elif node_name == "tools":
                    for msg in new_messages:
                        if isinstance(msg, ToolMessage):
                            console.print(f"âœ… å·¥å…·è¿”å›: {msg.content}")

                # âœ… è‡ªåŠ¨æ›´æ–°æ¶ˆæ¯å†å²
                messages = state["messages"]
```

**æ€»è¡Œæ•°ï¼š212 è¡Œï¼ˆåŒ…å« UI å‡½æ•°å’Œæ‰€æœ‰é€»è¾‘ï¼‰**

---

## æ‰§è¡Œæµç¨‹å¯¹æ¯”

### 03 çš„æ‰§è¡Œæµç¨‹ï¼ˆæ‰‹åŠ¨æ§åˆ¶ï¼‰

```
ç”¨æˆ·è¾“å…¥: "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿå¸®æˆ‘ç®— 2+3"
  â†“
session.add_user_message(...)  â† æ‰‹åŠ¨
  â†“
agent.chat(user_input, history)  â† è¿›å…¥ Agent
  â†“
  [Agent å†…éƒ¨ - 186 è¡Œ]
  â”œâ”€ for iteration in range(5):  â† æ‰‹åŠ¨å¾ªç¯
  â”‚    â”œâ”€ response = llm_with_tools.invoke(...)  â† æ‰‹åŠ¨è°ƒç”¨
  â”‚    â”œâ”€ æ‰‹åŠ¨åˆå¹¶ valid/invalid tool_calls (20 è¡Œ)
  â”‚    â”œâ”€ if not all_tool_calls: return  â† æ‰‹åŠ¨åˆ¤æ–­
  â”‚    â”œâ”€ æ‰‹åŠ¨åˆ›å»º clean_response
  â”‚    â”œâ”€ for tool_call in all_tool_calls:  â† æ‰‹åŠ¨éå†
  â”‚    â”‚    â”œâ”€ æ‰‹åŠ¨æŸ¥æ‰¾å·¥å…·
  â”‚    â”‚    â”œâ”€ result = tool.invoke(...)  â† æ‰‹åŠ¨æ‰§è¡Œ
  â”‚    â”‚    â”œâ”€ æ‰‹åŠ¨åˆ›å»º ToolMessage
  â”‚    â”‚    â””â”€ messages.append(ToolMessage(...))
  â”‚    â””â”€ å›åˆ°å¾ªç¯é¡¶éƒ¨
  â””â”€ return reply, tool_calls_made
  â†“
session.add_assistant_message(reply)  â† æ‰‹åŠ¨
  â†“
print_assistant(reply, tool_calls)  â† ä¸€æ¬¡æ€§æ‰“å°ï¼ˆæ— æ³•çœ‹åˆ°ä¸­é—´è¿‡ç¨‹ï¼‰
```

**é—®é¢˜ï¼š**
- âŒ æ¯ä¸€æ­¥éƒ½æ˜¯æ‰‹åŠ¨çš„
- âŒ æ— æ³•å®æ—¶çœ‹åˆ°å·¥å…·è°ƒç”¨è¿‡ç¨‹
- âŒ ä»£ç åˆ†æ•£åœ¨å¤šä¸ªæ–‡ä»¶
- âŒ 100+ è¡Œèƒ¶æ°´ä»£ç 

### 06 çš„æ‰§è¡Œæµç¨‹ï¼ˆè‡ªåŠ¨åŒ–ï¼‰

```
ç”¨æˆ·è¾“å…¥: "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿå¸®æˆ‘ç®— 2+3"
  â†“
messages.append(HumanMessage(...))
  â†“
app.stream({"messages": messages})  â† ä¸€æ¬¡è°ƒç”¨
  â†“
  [LangGraph è‡ªåŠ¨æ‰§è¡Œ]
  START
    â†“
  model èŠ‚ç‚¹ âœ…
    â”œâ”€ LLM å†³å®šè°ƒç”¨ get_current_time
    â”œâ”€ è¿”å› AIMessage(tool_calls=[...])
    â””â”€ å®æ—¶æ‰“å°: "ğŸ”§ è°ƒç”¨å·¥å…·: get_current_time(...)"
    â†“
  should_continue() â†’ "tools"  âœ…
    â†“
  tools èŠ‚ç‚¹ âœ…
    â”œâ”€ ToolNode è‡ªåŠ¨æ‰§è¡Œ get_current_time
    â”œâ”€ è¿”å› ToolMessage("å½“å‰æ—¶é—´æ˜¯...")
    â””â”€ å®æ—¶æ‰“å°: "âœ… å·¥å…·è¿”å›: å½“å‰æ—¶é—´æ˜¯..."
    â†“
  model èŠ‚ç‚¹ âœ…
    â”œâ”€ LLM å†³å®šè°ƒç”¨ calculator
    â”œâ”€ è¿”å› AIMessage(tool_calls=[...])
    â””â”€ å®æ—¶æ‰“å°: "ğŸ”§ è°ƒç”¨å·¥å…·: calculator(...)"
    â†“
  should_continue() â†’ "tools"  âœ…
    â†“
  tools èŠ‚ç‚¹ âœ…
    â”œâ”€ ToolNode è‡ªåŠ¨æ‰§è¡Œ calculator
    â”œâ”€ è¿”å› ToolMessage("è®¡ç®—ç»“æœ: 2+3=5")
    â””â”€ å®æ—¶æ‰“å°: "âœ… å·¥å…·è¿”å›: è®¡ç®—ç»“æœ: 2+3=5"
    â†“
  model èŠ‚ç‚¹ âœ…
    â”œâ”€ LLM ç”Ÿæˆæœ€ç»ˆå›å¤
    â”œâ”€ è¿”å› AIMessage("ç°åœ¨æ˜¯... 2+3=5")
    â””â”€ å®æ—¶æ‰“å°: "ğŸ¤– Assistant: ç°åœ¨æ˜¯... 2+3=5"
    â†“
  should_continue() â†’ END  âœ…
  â†“
è‡ªåŠ¨æ›´æ–° messagesï¼ˆåŒ…å«æ‰€æœ‰ AI/Tool æ¶ˆæ¯ï¼‰
```

**ä¼˜åŠ¿ï¼š**
- âœ… ä¸€æ¬¡è°ƒç”¨ï¼ŒLangGraph è‡ªåŠ¨æ‰§è¡Œ
- âœ… å®æ—¶å±•ç¤ºæ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡º
- âœ… æ‰€æœ‰é€»è¾‘åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­
- âœ… ä»… 30 è¡Œä¸»å¾ªç¯ä»£ç 

---

## ä»£ç é‡å¯¹æ¯”ï¼ˆåŒä¸€åŠŸèƒ½ï¼‰

| ç»„ä»¶ | 03 ä»£ç é‡ | 06 ä»£ç é‡ | å‡å°‘ |
|------|-----------|-----------|------|
| **å·¥å…·è°ƒç”¨é€»è¾‘** | 100+ è¡Œï¼ˆagent.py:78-178ï¼‰ | 1 è¡Œï¼ˆ`ToolNode(tools)`ï¼‰ | 99% â¬‡ï¸ |
| **çŠ¶æ€ç®¡ç†** | 98 è¡Œï¼ˆsession.pyï¼‰ | 0 è¡Œï¼ˆç”¨åˆ—è¡¨ï¼‰ | 100% â¬‡ï¸ |
| **è·¯ç”±é€»è¾‘** | åˆ†æ•£åœ¨å¾ªç¯ä¸­ | 3 è¡Œï¼ˆ`should_continue`ï¼‰ | æ˜ç¡®åŒ– âœ… |
| **é”™è¯¯å¤„ç†** | 20+ è¡Œ | 0 è¡Œï¼ˆToolNode è‡ªåŠ¨ï¼‰ | 100% â¬‡ï¸ |
| **ä¸»å¾ªç¯** | 126 è¡Œ | 30 è¡Œ | 76% â¬‡ï¸ |
| **æ€»è®¡** | ~400 è¡Œ | ~50 è¡Œï¼ˆä¸å« UIï¼‰ | 87% â¬‡ï¸ |

---

## å…³é”®å·®å¼‚æ€»ç»“

| ç»´åº¦ | 03-interactive | 06-tui |
|------|----------------|--------|
| **æ¶æ„æ€ç»´** | é¢å‘å¯¹è±¡ + æ‰‹åŠ¨æ§åˆ¶ | å›¾æ‰§è¡Œ + å£°æ˜å¼ |
| **å·¥å…·æ‰§è¡Œ** | `for tool_call in ...: tool.invoke(...)` | `ToolNode(tools)` |
| **çŠ¶æ€ç®¡ç†** | `Session` ç±»ï¼ˆ98 è¡Œï¼‰ | `messages` åˆ—è¡¨ |
| **è·¯ç”±å†³ç­–** | `if not all_tool_calls: return` | `should_continue()` æ¡ä»¶è¾¹ |
| **å¾ªç¯æ§åˆ¶** | `for iteration in range(5)` | LangGraph è‡ªåŠ¨ |
| **é”™è¯¯å¤„ç†** | 20+ è¡Œä¿®å¤ä»£ç  | ToolNode è‡ªåŠ¨ |
| **å®æ—¶å±•ç¤º** | âŒ æ— ï¼ˆä¸€æ¬¡æ€§è¿”å›ï¼‰ | âœ… æœ‰ï¼ˆæµå¼æ‰§è¡Œï¼‰ |
| **å¯ç»´æŠ¤æ€§** | âŒ ä½ï¼ˆä»£ç åˆ†æ•£ï¼‰ | âœ… é«˜ï¼ˆä»£ç é›†ä¸­ï¼‰ |

---

## ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿ

### 03 çš„é—®é¢˜ï¼š**æœ‰ bind_toolsï¼Œæ—  LangGraph**

```python
# 03 çš„æ–¹å¼
llm_with_tools = llm.bind_tools(tools)  # âœ… è¿™ä¸€æ­¥æ˜¯å¯¹çš„

# ä½†æ¥ä¸‹æ¥å…¨æ˜¯æ‰‹åŠ¨çš„...
for iteration in range(max_iterations):  # âŒ æ‰‹åŠ¨å¾ªç¯
    response = llm_with_tools.invoke(...)  # âŒ æ‰‹åŠ¨è°ƒç”¨
    for tool_call in response.tool_calls:  # âŒ æ‰‹åŠ¨éå†
        result = self.tools_map[tool_name].invoke(tool_args)  # âŒ æ‰‹åŠ¨æ‰§è¡Œ
        messages.append(ToolMessage(...))  # âŒ æ‰‹åŠ¨æ·»åŠ 
```

### 06 çš„é©æ–°ï¼š**bind_tools + LangGraph = è‡ªåŠ¨åŒ–**

```python
# 06 çš„æ–¹å¼
llm_with_tools = llm.bind_tools(tools)  # âœ… å£°æ˜å·¥å…·
tool_node = ToolNode(tools)  # âœ… è‡ªåŠ¨æ‰§è¡Œå™¨
graph.add_node("model", ...)  # âœ… å£°æ˜èŠ‚ç‚¹
graph.add_node("tools", tool_node)  # âœ… å£°æ˜èŠ‚ç‚¹
graph.add_conditional_edges(...)  # âœ… å£°æ˜è·¯ç”±

# ä½¿ç”¨
app.stream({"messages": messages})  # âœ… ä¸€è¡Œæå®šï¼
```

---

## ğŸ¯ ç»“è®º

**03 è½åçš„æ ¹æœ¬åŸå› ï¼šæ²¡æœ‰åˆ©ç”¨ LangGraph çš„è‡ªåŠ¨åŒ–èƒ½åŠ›**

- è™½ç„¶ç”¨äº† `bind_tools`ï¼Œä½†è¿˜åœ¨ç”¨å‘½ä»¤å¼ç¼–ç¨‹ï¼ˆæ‰‹åŠ¨å¾ªç¯ã€æ‰‹åŠ¨è°ƒç”¨ã€æ‰‹åŠ¨ç®¡ç†ï¼‰
- LangGraph æä¾›äº†å£°æ˜å¼ç¼–ç¨‹æ¨¡å‹ï¼ˆå®šä¹‰å›¾ç»“æ„ï¼Œè‡ªåŠ¨æ‰§è¡Œï¼‰
- ä»£ç ä» ~400 è¡Œå‡å°‘åˆ° ~50 è¡Œï¼Œå‡å°‘ 87%
- ç»´æŠ¤æ€§ã€å¯è¯»æ€§ã€ç”¨æˆ·ä½“éªŒå…¨é¢æå‡

**ä» 03 åˆ° 06 ä¸æ˜¯æ”¹è¿›ï¼Œæ˜¯èŒƒå¼è½¬å˜ï¼** ğŸš€
