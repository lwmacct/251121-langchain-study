#!/usr/bin/env -S uv run python
"""
LangGraph TUI å·¥å…·è°ƒç”¨æ¼”ç¤º - ä½¿ç”¨ Rich åº“çš„ç»ˆç«¯äº¤äº’ç•Œé¢

æ¼”ç¤º LangGraph å·¥å…·è°ƒç”¨åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ—¶é—´æŸ¥è¯¢ã€è®¡ç®—å™¨ç­‰å·¥å…·ï¼Œå¹¶é€šè¿‡ Rich åº“æä¾›å‹å¥½çš„ç»ˆç«¯ç•Œé¢
"""


import operator
import os
from typing import Annotated, Sequence, TypedDict

from langchain_core.messages import AnyMessage, HumanMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.prompt import Prompt
from rich import box

# Import tools from shared workspace library
from m_tools import get_current_time, calculator

# ===== åˆå§‹åŒ– =====
console = Console()

# é…ç½® LLM
api_key = os.getenv("OPENROUTER_API_KEY")
if not api_key:
    raise RuntimeError("é…ç½®é”™è¯¯:æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ OPENROUTER_API_KEY")

llm = ChatOpenAI(
    model="anthropic/claude-sonnet-4.5",
    base_url=os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1"),
    api_key=api_key,
)

# ===== é…ç½®å·¥å…· =====
# å·¥å…·åˆ—è¡¨ï¼ˆä» workspace åº“å¯¼å…¥ï¼‰
tool_list = [get_current_time, calculator]

# åˆ›å»ºå·¥å…·èŠ‚ç‚¹
tool_node = ToolNode(tool_list)

# å°†å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
llm_with_tools = llm.bind_tools(tool_list)


# ===== å®šä¹‰çŠ¶æ€ =====
class State(TypedDict):
    messages: Annotated[Sequence[AnyMessage], operator.add]


# ===== å®šä¹‰èŠ‚ç‚¹ =====
def call_model(state: State) -> State:
    """è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·ï¼‰å¹¶æŠŠå›å¤è¿½åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨"""
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}


def should_continue(state: State):
    """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è°ƒç”¨å·¥å…·"""
    messages = state["messages"]
    last_message = messages[-1]
    # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æœ‰ tool_callsï¼Œåˆ™è·¯ç”±åˆ°å·¥å…·èŠ‚ç‚¹
    if last_message.tool_calls:
        return "tools"
    # å¦åˆ™ç»“æŸ
    return END


# ===== æ„å»ºå›¾ =====
graph = StateGraph(State)

# æ·»åŠ èŠ‚ç‚¹
graph.add_node("model", call_model)
graph.add_node("tools", tool_node)

# æ·»åŠ è¾¹
graph.add_edge(START, "model")
graph.add_conditional_edges("model", should_continue, {"tools": "tools", END: END})
graph.add_edge("tools", "model")  # å·¥å…·æ‰§è¡Œåè¿”å›æ¨¡å‹

# ç¼–è¯‘å›¾
app = graph.compile()


# ===== UI å‡½æ•° =====
def print_welcome():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
    welcome_text = """# ğŸ¤– TUI å·¥å…·è°ƒç”¨æ¼”ç¤º

**å¯ç”¨å·¥å…·ï¼š**
- ğŸ•’ `get_current_time` - è·å–å½“å‰æ—¶é—´
- ğŸ”¢ `calculator` - æ‰§è¡Œæ•°å­¦è®¡ç®—

**ç¤ºä¾‹é—®é¢˜ï¼š**
- ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ
- å¸®æˆ‘è®¡ç®— 42 * 7
- ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±
- ä½ é¢„æµ‹äººå·¥æ™ºèƒ½ agi åœ¨å“ªä¸€å¹´èƒ½å®ç°, é‚£æ—¶å€™ æ˜¯å‡ å‡ å¹´äº†, ä½ æ¥è®¡ç®—ä¸€ä¸‹

è¾“å…¥ `exit` æˆ– `quit` é€€å‡º
"""
    console.print(Panel(Markdown(welcome_text), box=box.ROUNDED, border_style="cyan"))


def print_user_message(message: str):
    """æ‰“å°ç”¨æˆ·æ¶ˆæ¯"""
    console.print(f"\n[bold cyan]ğŸ‘¤ You:[/bold cyan] {message}")


def print_tool_call(tool_call):
    """æ‰“å°å·¥å…·è°ƒç”¨ä¿¡æ¯"""
    tool_name = tool_call.get("name", "unknown")
    tool_args = tool_call.get("args", {})
    console.print(f"[yellow]ğŸ”§ è°ƒç”¨å·¥å…·:[/yellow] {tool_name}({tool_args})")


def print_assistant_message(content: str, has_tool_calls: bool = False):
    """æ‰“å°åŠ©æ‰‹æ¶ˆæ¯"""
    if content:
        console.print(f"[bold green]ğŸ¤– Assistant:[/bold green] {content}")
    if not has_tool_calls and not content:
        console.print("[dim]ç­‰å¾…å·¥å…·æ‰§è¡Œ...[/dim]")


# ===== ä¸»å¾ªç¯ =====
def main():
    """ä¸»å‡½æ•°"""
    print_welcome()

    # åˆå§‹åŒ–æ¶ˆæ¯å†å²
    messages = []

    try:
        while True:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = Prompt.ask("\n[bold cyan]ğŸ’¬ You[/bold cyan]")

            # æ£€æŸ¥é€€å‡ºå‘½ä»¤
            if user_input.lower() in ["exit", "quit", "q"]:
                console.print("\n[yellow]ğŸ‘‹ å†è§ï¼[/yellow]")
                break

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            messages.append(HumanMessage(content=user_input))

            # è°ƒç”¨ LangGraph åº”ç”¨
            console.print("[dim]æ­£åœ¨æ€è€ƒ...[/dim]")

            # æµå¼æ‰§è¡Œå›¾
            for output in app.stream({"messages": messages}):
                # è¾“å‡ºåŒ…å«èŠ‚ç‚¹åç§°å’ŒçŠ¶æ€
                for node_name, state in output.items():
                    new_messages = state["messages"]

                    # å¤„ç†æ¨¡å‹èŠ‚ç‚¹çš„è¾“å‡º
                    if node_name == "model":
                        last_message = new_messages[-1]

                        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨
                        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                            for tool_call in last_message.tool_calls:
                                print_tool_call(tool_call)

                        # å¦‚æœæœ‰å†…å®¹
                        if last_message.content:
                            print_assistant_message(last_message.content)

                    # å¤„ç†å·¥å…·èŠ‚ç‚¹çš„è¾“å‡º
                    elif node_name == "tools":
                        for msg in new_messages:
                            if isinstance(msg, ToolMessage):
                                console.print(f"[green]âœ… å·¥å…·è¿”å›:[/green] {msg.content}")

                    # æ›´æ–°æ¶ˆæ¯å†å²
                    messages = state["messages"]

    except KeyboardInterrupt:
        console.print("\n\n[yellow]ğŸ‘‹ ä¼šè¯å·²ä¸­æ–­[/yellow]")
    except Exception as e:
        console.print(f"\n[red]âŒ é”™è¯¯: {e}[/red]")


if __name__ == "__main__":
    main()
